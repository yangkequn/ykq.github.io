<!doctype html><html lang=en dir=" ltr "><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="6月主要工作：学习强化学习。 # 书学了两本。算是入门，研究各种最新SOTA技术。强化学习框架 最后打算用actor-critic框架来做。 actor critic 模型
flowchart LR enviroment --> observation observation --> Hearbeat --HearbeatVAE -->HBZ observation --> Audio HBZ --> MDN-RNN(Dynamic,NextState) --> critic Audio --AudioVAE --> AZ --> MDN-RNN HBZ-->critic AZ-->critic enviroment --reward--> critic 世界模型 https://zhuanlan.zhihu.com/p/42537455 # https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951 看vae # https://worldmodels.github.io/ # https://zhuanlan.zhihu.com/p/384420701 DreamerV2实现代码 # https://zhuanlan.zhihu.com/p/363774920 DreamerV2 讲得很详细 # https://zhuanlan.zhihu.com/p/34998569 VAE的实现原理 https://github.com/bojone/vae/blob/master/cvae_keras.py # 其中提到Action 作用于隐态，得下一个状态，应该是一个独立函数，隐态之间遵守 min KL
flowchart LR enviroment --> observation observation --> Hearbeat --HearbeatVAE -->HBZ --> MDN-RNN(Dynamic,NextState) --> controller controller --> ActionZ --> MDN-RNN HBZ-->controller ActionZ --> enviroment flowchart LR enviroment --> observation observation --> Hearbeat --HearbeatVAE -->HBZ --> MDN-RNN(Dynamic,NextState) --> controller controller --> ActionZ --> MDN-RNN controller --> Reward controller --> Value HBZ-->controller ActionZ --> enviroment 回报如何引入。如果改进模型 Dreamer v2 是否是同一个东西，如何改进"><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="study Reinforcement Learning"><meta property="og:description" content="6月主要工作：学习强化学习。 # 书学了两本。算是入门，研究各种最新SOTA技术。强化学习框架 最后打算用actor-critic框架来做。 actor critic 模型
flowchart LR enviroment --> observation observation --> Hearbeat --HearbeatVAE -->HBZ observation --> Audio HBZ --> MDN-RNN(Dynamic,NextState) --> critic Audio --AudioVAE --> AZ --> MDN-RNN HBZ-->critic AZ-->critic enviroment --reward--> critic 世界模型 https://zhuanlan.zhihu.com/p/42537455 # https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951 看vae # https://worldmodels.github.io/ # https://zhuanlan.zhihu.com/p/384420701 DreamerV2实现代码 # https://zhuanlan.zhihu.com/p/363774920 DreamerV2 讲得很详细 # https://zhuanlan.zhihu.com/p/34998569 VAE的实现原理 https://github.com/bojone/vae/blob/master/cvae_keras.py # 其中提到Action 作用于隐态，得下一个状态，应该是一个独立函数，隐态之间遵守 min KL
flowchart LR enviroment --> observation observation --> Hearbeat --HearbeatVAE -->HBZ --> MDN-RNN(Dynamic,NextState) --> controller controller --> ActionZ --> MDN-RNN HBZ-->controller ActionZ --> enviroment flowchart LR enviroment --> observation observation --> Hearbeat --HearbeatVAE -->HBZ --> MDN-RNN(Dynamic,NextState) --> controller controller --> ActionZ --> MDN-RNN controller --> Reward controller --> Value HBZ-->controller ActionZ --> enviroment 回报如何引入。如果改进模型 Dreamer v2 是否是同一个东西，如何改进"><meta property="og:type" content="article"><meta property="og:url" content="https://kequnyang.com/okr/2022-06-iam26-model/"><meta property="article:section" content="okr"><meta property="article:published_time" content="2022-06-24T11:02:45+08:00"><meta property="article:modified_time" content="2022-08-15T07:47:30+08:00"><title>study Reinforcement Learning | To Build, I Live</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.dd05bb7cb8e7cc9da19dd8062472a16791465d468ff2c52bf4f137e6d138cbda.css integrity="sha256-3QW7fLjnzJ2hndgGJHKhZ5FGXUaP8sUr9PE35tE4y9o=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.bd145d0880e670e2739053920108a93c1276bc68636290d46a7126d0a5ced549.js integrity="sha256-vRRdCIDmcOJzkFOSAQipPBJ2vGhjYpDUanEm0KXO1Uk=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=" ltr "><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>To Build, I Live</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/forcasts/ target=_blank rel=noopener>forcasts / 预言</a></li><li><a href=/ideas/ target=_blank rel=noopener>ideas / 想法</a></li><li><a href=/okr/2022-09_iam26/ target=_blank rel=noopener>Todo this month</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>study Reinforcement Learning</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><a href=#6月主要工作学习强化学习>6月主要工作：学习强化学习。</a><ul><li><ul><li><a href=#世界模型-httpszhuanlanzhihucomp42537455>世界模型 <a href=https://zhuanlan.zhihu.com/p/42537455>https://zhuanlan.zhihu.com/p/42537455</a></a></li><li><a href=#httpsblogcsdnnetkuxiaoqushihuaiarticledetails109657951-看vae><a href=https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951>https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951</a> 看vae</a></li><li><a href=#httpsworldmodelsgithubio><a href=https://worldmodels.github.io/>https://worldmodels.github.io/</a></a></li><li><a href=#httpszhuanlanzhihucomp384420701-dreamerv2实现代码><a href=https://zhuanlan.zhihu.com/p/384420701>https://zhuanlan.zhihu.com/p/384420701</a> DreamerV2实现代码</a></li><li><a href=#httpszhuanlanzhihucomp363774920-dreamerv2-讲得很详细><a href=https://zhuanlan.zhihu.com/p/363774920>https://zhuanlan.zhihu.com/p/363774920</a> DreamerV2 讲得很详细</a></li><li><a href=#httpszhuanlanzhihucomp34998569-vae的实现原理-httpsgithubcombojonevaeblobmastercvae_keraspy><a href=https://zhuanlan.zhihu.com/p/34998569>https://zhuanlan.zhihu.com/p/34998569</a> VAE的实现原理 <a href=https://github.com/bojone/vae/blob/master/cvae_keras.py>https://github.com/bojone/vae/blob/master/cvae_keras.py</a></a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h1 id=6月主要工作学习强化学习>6月主要工作：学习强化学习。
<a class=anchor href=#6%e6%9c%88%e4%b8%bb%e8%a6%81%e5%b7%a5%e4%bd%9c%e5%ad%a6%e4%b9%a0%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0>#</a></h1><pre><code>书学了两本。算是入门，研究各种最新SOTA技术。强化学习框架
最后打算用actor-critic框架来做。
</code></pre><p>actor critic 模型</p><div class=mermaid>flowchart LR
enviroment --> observation
observation --> Hearbeat --HearbeatVAE -->HBZ
observation --> Audio
HBZ --> MDN-RNN(Dynamic,NextState) --> critic
Audio --AudioVAE --> AZ --> MDN-RNN
HBZ-->critic
AZ-->critic
enviroment --reward--> critic</div><h3 id=世界模型-httpszhuanlanzhihucomp42537455>世界模型 <a href=https://zhuanlan.zhihu.com/p/42537455>https://zhuanlan.zhihu.com/p/42537455</a>
<a class=anchor href=#%e4%b8%96%e7%95%8c%e6%a8%a1%e5%9e%8b-httpszhuanlanzhihucomp42537455>#</a></h3><h3 id=httpsblogcsdnnetkuxiaoqushihuaiarticledetails109657951-看vae><a href=https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951>https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951</a> 看vae
<a class=anchor href=#httpsblogcsdnnetkuxiaoqushihuaiarticledetails109657951-%e7%9c%8bvae>#</a></h3><h3 id=httpsworldmodelsgithubio><a href=https://worldmodels.github.io/>https://worldmodels.github.io/</a>
<a class=anchor href=#httpsworldmodelsgithubio>#</a></h3><h3 id=httpszhuanlanzhihucomp384420701-dreamerv2实现代码><a href=https://zhuanlan.zhihu.com/p/384420701>https://zhuanlan.zhihu.com/p/384420701</a> DreamerV2实现代码
<a class=anchor href=#httpszhuanlanzhihucomp384420701-dreamerv2%e5%ae%9e%e7%8e%b0%e4%bb%a3%e7%a0%81>#</a></h3><h3 id=httpszhuanlanzhihucomp363774920-dreamerv2-讲得很详细><a href=https://zhuanlan.zhihu.com/p/363774920>https://zhuanlan.zhihu.com/p/363774920</a> DreamerV2 讲得很详细
<a class=anchor href=#httpszhuanlanzhihucomp363774920-dreamerv2-%e8%ae%b2%e5%be%97%e5%be%88%e8%af%a6%e7%bb%86>#</a></h3><h3 id=httpszhuanlanzhihucomp34998569-vae的实现原理-httpsgithubcombojonevaeblobmastercvae_keraspy><a href=https://zhuanlan.zhihu.com/p/34998569>https://zhuanlan.zhihu.com/p/34998569</a> VAE的实现原理 <a href=https://github.com/bojone/vae/blob/master/cvae_keras.py>https://github.com/bojone/vae/blob/master/cvae_keras.py</a>
<a class=anchor href=#httpszhuanlanzhihucomp34998569-vae%e7%9a%84%e5%ae%9e%e7%8e%b0%e5%8e%9f%e7%90%86-httpsgithubcombojonevaeblobmastercvae_keraspy>#</a></h3><p>其中提到Action 作用于隐态，得下一个状态，应该是一个独立函数，隐态之间遵守 min KL</p><div class=mermaid>flowchart LR
enviroment --> observation
observation --> Hearbeat --HearbeatVAE -->HBZ --> MDN-RNN(Dynamic,NextState) --> controller
controller --> ActionZ --> MDN-RNN
HBZ-->controller
ActionZ --> enviroment</div><div class=mermaid>flowchart LR
enviroment --> observation
observation --> Hearbeat --HearbeatVAE -->HBZ --> MDN-RNN(Dynamic,NextState) --> controller
controller --> ActionZ --> MDN-RNN
controller --> Reward
controller --> Value
HBZ-->controller
ActionZ --> enviroment</div><p>回报如何引入。如果改进模型
Dreamer v2 是否是同一个东西，如何改进</p><p>用于声音的两点改进
1.使用sgd
2.正则化约束使用很低的权重</p><div class=mermaid>flowchart LR
enviroment --> observation
observation --> Hearbeat --HearbeatVAE -->HBZ --> MDN-RNN(Dynamic,NextState)
observation --> Audio --AudioVAE -->AZ --> MDN-RNN(Dynamic,NextState)
AZ --> controller
MDN-RNN(Dynamic,NextState) --> controller
HBZ-->controller
controller-->NewAZ --> enviroment</div></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script><script src=https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js></script>
<script>mermaid.initialize({startOnLoad:!0})</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#6月主要工作学习强化学习>6月主要工作：学习强化学习。</a><ul><li><ul><li><a href=#世界模型-httpszhuanlanzhihucomp42537455>世界模型 <a href=https://zhuanlan.zhihu.com/p/42537455>https://zhuanlan.zhihu.com/p/42537455</a></a></li><li><a href=#httpsblogcsdnnetkuxiaoqushihuaiarticledetails109657951-看vae><a href=https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951>https://blog.csdn.net/KuXiaoQuShiHuai/article/details/109657951</a> 看vae</a></li><li><a href=#httpsworldmodelsgithubio><a href=https://worldmodels.github.io/>https://worldmodels.github.io/</a></a></li><li><a href=#httpszhuanlanzhihucomp384420701-dreamerv2实现代码><a href=https://zhuanlan.zhihu.com/p/384420701>https://zhuanlan.zhihu.com/p/384420701</a> DreamerV2实现代码</a></li><li><a href=#httpszhuanlanzhihucomp363774920-dreamerv2-讲得很详细><a href=https://zhuanlan.zhihu.com/p/363774920>https://zhuanlan.zhihu.com/p/363774920</a> DreamerV2 讲得很详细</a></li><li><a href=#httpszhuanlanzhihucomp34998569-vae的实现原理-httpsgithubcombojonevaeblobmastercvae_keraspy><a href=https://zhuanlan.zhihu.com/p/34998569>https://zhuanlan.zhihu.com/p/34998569</a> VAE的实现原理 <a href=https://github.com/bojone/vae/blob/master/cvae_keras.py>https://github.com/bojone/vae/blob/master/cvae_keras.py</a></a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>