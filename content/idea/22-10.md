---
title: "22 10"
date: 2022-10-11T07:16:13+08:00
draft: true
---

# 关于调权loss中的权不敏感的延伸：
   最近在这个问题上的仔细斟酌让我在炼丹上有一种炉火纯青的感觉。1.可以监视各部分原始loss,从原始loss的分别下降趋势和水平可以看出模型对两部分loss耦合水平的理解。2.任何时候可以关闭一部分loss的反向传播，用更单一的目标控制系统的演进方向，以避免无法突破的局部最优。可以反复切换目标。再最终融合目标。个人感觉这个办法可以极大加速收敛。

# 采用高级特征或低级特征作为状态表征
   先前百度自动驾驶用抽象的特征向量而非视觉输入来编码车辆的状态切换，大概可以对模型做40倍加速。最近我采用相似思路感觉超赞。特别是如果采用更接近底层视觉向量可以用于约束高级特征，在时序预测上，可以给出极高的性能。

# 高斯采样用于梯度回归性
   传统的梯度学习只涉及梯度的回归。我发现对梯度多做一次采样，再回归是个非常了不起的思路。1.它提供了一种超越样本，在更高的间接性中评价性能的能力。2.它能更好地约束不同维度的独立性（更低相关性）

# 如何一般性地构建（时序依赖）注意力分布图
   这个问题的价值很高。但其实很简单: 对原始信息做消融，判断对目标性能的扰动。将时序排序的扰动做积分，再作为一个独立的损失通道，我们就得到了完美而平滑的注意力分布图。