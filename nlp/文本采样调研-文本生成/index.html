<!doctype html><html lang=en dir=" ltr "><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="这个工作尝试使用文本生成的内容作为学习内容。看看这个思路是否具有可行性 # 文本生成的相关工具 # MobileBERT tensorflow 文本处理相关 https://www.tensorflow.org/tutorials/text/transformer
Gpt-2 # Gpt-2 在线测试。 https://deepai.org/machine-learning-model/text-generator https://transformer.huggingface.co/doc/distil-gpt2
Gpt-2 的测试结构表明： 没有fine-tune, 文本生成的内容绝对不能作为学习材料，因为可靠性太差。
Gpt-3 # Gpt-3的测试 案例：用于媒体广告灵感生成 测试地址
像这样的生产，不是以文字打头，而是用基于内容的随机采样，是可以用于生成初始的讲解数据的 但是还是有大量不相干的内容采样。需要平台整理，
我意识到，文本生成的内容既不可控又不可靠。用于产生学习的内容, 其实需要的并不是文本采样工具。文本生成只是我接触到的相关的概念。但是我需要什么样的工具应该重新分析
VAE 和 SEQ2SEQ 的文本生成 # 【NLP笔记】文本生成基础与方案梳理 评： * 指定关键词生成内容是可能的。 * 但是是不是总是生成 * 逻辑上是否合理，没有保证 * 但是只要有一些显然是合理的生成内容，就可以部分解决问题 文本生成概述 2021-10-05 23:52:50 星期二
文本生成的实现办法，这个视频讲了挺多实现办法 # https://uai.greedyai.com/ai-open-courses/the-generation-problem-in-the-dialogue-system
10/06/2021 hugging face 提供的，基于GPT-2的文本生成 # https://huggingface.co/gpt2?text=A+long+time+ago%2C
2021-10-30 13:16:31"><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="文本采样调研 - 文本生成"><meta property="og:description" content="这个工作尝试使用文本生成的内容作为学习内容。看看这个思路是否具有可行性 # 文本生成的相关工具 # MobileBERT tensorflow 文本处理相关 https://www.tensorflow.org/tutorials/text/transformer
Gpt-2 # Gpt-2 在线测试。 https://deepai.org/machine-learning-model/text-generator https://transformer.huggingface.co/doc/distil-gpt2
Gpt-2 的测试结构表明： 没有fine-tune, 文本生成的内容绝对不能作为学习材料，因为可靠性太差。
Gpt-3 # Gpt-3的测试 案例：用于媒体广告灵感生成 测试地址
像这样的生产，不是以文字打头，而是用基于内容的随机采样，是可以用于生成初始的讲解数据的 但是还是有大量不相干的内容采样。需要平台整理，
我意识到，文本生成的内容既不可控又不可靠。用于产生学习的内容, 其实需要的并不是文本采样工具。文本生成只是我接触到的相关的概念。但是我需要什么样的工具应该重新分析
VAE 和 SEQ2SEQ 的文本生成 # 【NLP笔记】文本生成基础与方案梳理 评： * 指定关键词生成内容是可能的。 * 但是是不是总是生成 * 逻辑上是否合理，没有保证 * 但是只要有一些显然是合理的生成内容，就可以部分解决问题 文本生成概述 2021-10-05 23:52:50 星期二
文本生成的实现办法，这个视频讲了挺多实现办法 # https://uai.greedyai.com/ai-open-courses/the-generation-problem-in-the-dialogue-system
10/06/2021 hugging face 提供的，基于GPT-2的文本生成 # https://huggingface.co/gpt2?text=A+long+time+ago%2C
2021-10-30 13:16:31"><meta property="og:type" content="article"><meta property="og:url" content="https://kequnyang.com/nlp/%E6%96%87%E6%9C%AC%E9%87%87%E6%A0%B7%E8%B0%83%E7%A0%94-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90/"><meta property="article:section" content="nlp"><meta property="article:published_time" content="2021-03-17T09:19:16+08:00"><meta property="article:modified_time" content="2021-03-17T09:19:16+08:00"><title>文本采样调研 - 文本生成 | To Build, I Live</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.dd05bb7cb8e7cc9da19dd8062472a16791465d468ff2c52bf4f137e6d138cbda.css integrity="sha256-3QW7fLjnzJ2hndgGJHKhZ5FGXUaP8sUr9PE35tE4y9o=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.55fbce67ad9711b91181e6285a002d016d17806fcfd5b5a324c3da113b84adf0.js integrity="sha256-VfvOZ62XEbkRgeYoWgAtAW0XgG/P1bWjJMPaETuErfA=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=" ltr "><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>To Build, I Live</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/forcasts/ target=_blank rel=noopener>forcasts / 预言</a></li><li><a href=/ideas/ target=_blank rel=noopener>ideas / 想法</a></li><li><a href=/okr/2022-10-meditation/ target=_blank rel=noopener>Todo Last Month</a></li><li><a href=/okr/2022-11-meditation/ target=_blank rel=noopener>Todo This Month</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>文本采样调研 - 文本生成</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><ul><li><a href=#这个工作尝试使用文本生成的内容作为学习内容看看这个思路是否具有可行性>这个工作尝试使用文本生成的内容作为学习内容。看看这个思路是否具有可行性</a></li></ul></li><li><a href=#文本生成的相关工具>文本生成的相关工具</a></li><li><a href=#gpt-2>Gpt-2</a></li><li><a href=#gpt-3>Gpt-3</a></li><li><a href=#vae-和-seq2seq-的文本生成>VAE 和 SEQ2SEQ 的文本生成</a></li></ul></li><li><a href=#文本生成的实现办法这个视频讲了挺多实现办法>文本生成的实现办法，这个视频讲了挺多实现办法</a><ul><li><ul><li><a href=#hugging-face-提供的基于gpt-2的文本生成>hugging face 提供的，基于GPT-2的文本生成</a></li></ul></li></ul></li></ul></nav></aside></header><article class=markdown><h3 id=这个工作尝试使用文本生成的内容作为学习内容看看这个思路是否具有可行性>这个工作尝试使用文本生成的内容作为学习内容。看看这个思路是否具有可行性
<a class=anchor href=#%e8%bf%99%e4%b8%aa%e5%b7%a5%e4%bd%9c%e5%b0%9d%e8%af%95%e4%bd%bf%e7%94%a8%e6%96%87%e6%9c%ac%e7%94%9f%e6%88%90%e7%9a%84%e5%86%85%e5%ae%b9%e4%bd%9c%e4%b8%ba%e5%ad%a6%e4%b9%a0%e5%86%85%e5%ae%b9%e7%9c%8b%e7%9c%8b%e8%bf%99%e4%b8%aa%e6%80%9d%e8%b7%af%e6%98%af%e5%90%a6%e5%85%b7%e6%9c%89%e5%8f%af%e8%a1%8c%e6%80%a7>#</a></h3><h2 id=文本生成的相关工具>文本生成的相关工具
<a class=anchor href=#%e6%96%87%e6%9c%ac%e7%94%9f%e6%88%90%e7%9a%84%e7%9b%b8%e5%85%b3%e5%b7%a5%e5%85%b7>#</a></h2><p>MobileBERT
tensorflow 文本处理相关
<a href=https://www.tensorflow.org/tutorials/text/transformer>https://www.tensorflow.org/tutorials/text/transformer</a></p><h2 id=gpt-2>Gpt-2
<a class=anchor href=#gpt-2>#</a></h2><p>Gpt-2 在线测试。
<a href=https://deepai.org/machine-learning-model/text-generator>https://deepai.org/machine-learning-model/text-generator</a>
<a href=https://transformer.huggingface.co/doc/distil-gpt2>https://transformer.huggingface.co/doc/distil-gpt2</a></p><p>Gpt-2 的测试结构表明：
没有fine-tune, 文本生成的内容绝对不能作为学习材料，因为可靠性太差。</p><h2 id=gpt-3>Gpt-3
<a class=anchor href=#gpt-3>#</a></h2><p>Gpt-3的测试
<a href=https://medium.com/ai-first/%E5%8F%B2%E4%B8%8A%E6%9C%80%E5%BC%B7gpt3%E6%A8%A1%E5%9E%8B-%E5%8F%AF%E4%BB%A5%E5%A6%82%E4%BD%95%E6%87%89%E7%94%A8-a66200aaa8bc title=用于媒体广告灵感生成>案例：用于媒体广告灵感生成</a>
<a href="https://fb.high5.ai/messenger?shortcode_id=lL-yhW2hi&ref=%7B%22id%22:%22lL-yhW2hi%22%7D" title=测试地址>测试地址</a></p><p>像这样的生产，不是以文字打头，而是用基于内容的随机采样，是可以用于生成初始的讲解数据的
但是还是有大量不相干的内容采样。需要平台整理，</p><p>我意识到，文本生成的内容既不可控又不可靠。用于产生学习的内容, 其实需要的并不是文本采样工具。文本生成只是我接触到的相关的概念。但是我需要什么样的工具应该重新分析</p><h2 id=vae-和-seq2seq-的文本生成>VAE 和 SEQ2SEQ 的文本生成
<a class=anchor href=#vae-%e5%92%8c-seq2seq-%e7%9a%84%e6%96%87%e6%9c%ac%e7%94%9f%e6%88%90>#</a></h2><blockquote><ol><li><a href=https://zhuanlan.zhihu.com/p/162035103 title=【NLP笔记】文本生成基础与方案梳理>【NLP笔记】文本生成基础与方案梳理</a></li></ol></blockquote><pre><code>评：
* 指定关键词生成内容是可能的。
* 但是是不是总是生成
* 逻辑上是否合理，没有保证
* 但是只要有一些显然是合理的生成内容，就可以部分解决问题
</code></pre><blockquote><ol start=2><li><a href=https://www.jiqizhixin.com/articles/2017-05-22 title=文本生成概述>文本生成概述</a></li></ol></blockquote><p>2021-10-05 23:52:50 星期二</p><h1 id=文本生成的实现办法这个视频讲了挺多实现办法>文本生成的实现办法，这个视频讲了挺多实现办法
<a class=anchor href=#%e6%96%87%e6%9c%ac%e7%94%9f%e6%88%90%e7%9a%84%e5%ae%9e%e7%8e%b0%e5%8a%9e%e6%b3%95%e8%bf%99%e4%b8%aa%e8%a7%86%e9%a2%91%e8%ae%b2%e4%ba%86%e6%8c%ba%e5%a4%9a%e5%ae%9e%e7%8e%b0%e5%8a%9e%e6%b3%95>#</a></h1><p><a href=https://uai.greedyai.com/ai-open-courses/the-generation-problem-in-the-dialogue-system>https://uai.greedyai.com/ai-open-courses/the-generation-problem-in-the-dialogue-system</a></p><p>10/06/2021
<img src=https://kequnyang.com/wp-content/uploads/2021/10/UntitledImage-1.png alt=UntitledImage title=UntitledImage.png border=0 width=599 height=366></p><h3 id=hugging-face-提供的基于gpt-2的文本生成>hugging face 提供的，基于GPT-2的文本生成
<a class=anchor href=#hugging-face-%e6%8f%90%e4%be%9b%e7%9a%84%e5%9f%ba%e4%ba%8egpt-2%e7%9a%84%e6%96%87%e6%9c%ac%e7%94%9f%e6%88%90>#</a></h3><p><a href="https://huggingface.co/gpt2?text=A+long+time+ago%2C">https://huggingface.co/gpt2?text=A+long+time+ago%2C</a></p><p>2021-10-30 13:16:31</p></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><ul><li><a href=#这个工作尝试使用文本生成的内容作为学习内容看看这个思路是否具有可行性>这个工作尝试使用文本生成的内容作为学习内容。看看这个思路是否具有可行性</a></li></ul></li><li><a href=#文本生成的相关工具>文本生成的相关工具</a></li><li><a href=#gpt-2>Gpt-2</a></li><li><a href=#gpt-3>Gpt-3</a></li><li><a href=#vae-和-seq2seq-的文本生成>VAE 和 SEQ2SEQ 的文本生成</a></li></ul></li><li><a href=#文本生成的实现办法这个视频讲了挺多实现办法>文本生成的实现办法，这个视频讲了挺多实现办法</a><ul><li><ul><li><a href=#hugging-face-提供的基于gpt-2的文本生成>hugging face 提供的，基于GPT-2的文本生成</a></li></ul></li></ul></li></ul></nav></div></aside></main></body></html>