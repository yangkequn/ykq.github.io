<!doctype html><html lang=en dir=" ltr "><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="1.milvus Milvus 是一款开源的、针对海量特征向量的相似性搜索引擎。 https://github.com/milvus-io/milvus 文档 https://milvus.io/cn/
各种各样的语料库，非常全，而且可以下载 冷眼-风雨飘摇 专注于python、自然语言处理 https://cold-eye.github.io/post/nlp-corpus/ 2021-09-01 13:39:39 星期三
text2vec引擎 推理速度可以满足实时性要求。https://github.com/NVIDIA/FasterTransformer ELECTRA模型 https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html 中文预训练模型 https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html https://github.com/ymcui/Chinese-ELECTRA 科大讯飞某个主要技术负责人的github https://github.com/ymcui 中文训练数据集扩大9倍后的效果 https://www.jiqizhixin.com/articles/2020-10-26-11
苏剑林的反省：吐槽贴：用ELECTRA、ALBERT之前，你真的了解它们吗？ https://bbs.huaweicloud.com/blogs/226675 苏剑林的博客 https://kexue.fm/
对bert 进行蒸馏，tinyBERT,推理速度提高9倍 https://zhuanlan.zhihu.com/p/94359189 这是很棒的模型，一来可以直接训练，二来，可以用来蒸馏后使用
最后，github 上找出了一个质量很不错的答案，来解决计算文本相似度的问题 https://github.com/shibing624/text2vec 具体实现包括wordVector 平均值法，以及small Bert 模型，重要的是这个是开箱可用的 https://www.sbert.net/index.html
2021-09-02 15:06:43 星期四 # fasterTransformer https://baike.baidu.com/item/Faster%20Transformer/23737285?fr=aladdin
最新的媲美Bert的模型 PRADO，pQRNN https://zhuanlan.zhihu.com/p/257934777 ：印象是虽然小，但是没有放出的代码实现。也没有中文版本的踩坑记录
2021-09-01 # "><meta name=theme-color content="#FFFFFF"><meta name=color-scheme content="light dark"><meta property="og:title" content="text2vec 与矢量索引引擎"><meta property="og:description" content="1.milvus Milvus 是一款开源的、针对海量特征向量的相似性搜索引擎。 https://github.com/milvus-io/milvus 文档 https://milvus.io/cn/
各种各样的语料库，非常全，而且可以下载 冷眼-风雨飘摇 专注于python、自然语言处理 https://cold-eye.github.io/post/nlp-corpus/ 2021-09-01 13:39:39 星期三
text2vec引擎 推理速度可以满足实时性要求。https://github.com/NVIDIA/FasterTransformer ELECTRA模型 https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html 中文预训练模型 https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html https://github.com/ymcui/Chinese-ELECTRA 科大讯飞某个主要技术负责人的github https://github.com/ymcui 中文训练数据集扩大9倍后的效果 https://www.jiqizhixin.com/articles/2020-10-26-11
苏剑林的反省：吐槽贴：用ELECTRA、ALBERT之前，你真的了解它们吗？ https://bbs.huaweicloud.com/blogs/226675 苏剑林的博客 https://kexue.fm/
对bert 进行蒸馏，tinyBERT,推理速度提高9倍 https://zhuanlan.zhihu.com/p/94359189 这是很棒的模型，一来可以直接训练，二来，可以用来蒸馏后使用
最后，github 上找出了一个质量很不错的答案，来解决计算文本相似度的问题 https://github.com/shibing624/text2vec 具体实现包括wordVector 平均值法，以及small Bert 模型，重要的是这个是开箱可用的 https://www.sbert.net/index.html
2021-09-02 15:06:43 星期四 # fasterTransformer https://baike.baidu.com/item/Faster%20Transformer/23737285?fr=aladdin
最新的媲美Bert的模型 PRADO，pQRNN https://zhuanlan.zhihu.com/p/257934777 ：印象是虽然小，但是没有放出的代码实现。也没有中文版本的踩坑记录
2021-09-01 # "><meta property="og:type" content="article"><meta property="og:url" content="https://kequnyang.com/nlp/text2vec-%E4%B8%8E%E7%9F%A2%E9%87%8F%E7%B4%A2%E5%BC%95%E5%BC%95%E6%93%8E/"><meta property="article:section" content="nlp"><meta property="article:published_time" content="2021-09-01T21:58:16+08:00"><meta property="article:modified_time" content="2021-09-01T21:58:16+08:00"><title>text2vec 与矢量索引引擎 | To Build, I Live</title><link rel=manifest href=/manifest.json><link rel=icon href=/favicon.png type=image/x-icon><link rel=stylesheet href=/book.min.dd05bb7cb8e7cc9da19dd8062472a16791465d468ff2c52bf4f137e6d138cbda.css integrity="sha256-3QW7fLjnzJ2hndgGJHKhZ5FGXUaP8sUr9PE35tE4y9o=" crossorigin=anonymous><script defer src=/flexsearch.min.js></script>
<script defer src=/en.search.min.a16a8e42ecf4ac21e57d264bedff73e29f042fa46539ee5fe9ac3eed9e6315a0.js integrity="sha256-oWqOQuz0rCHlfSZL7f9z4p8EL6RlOe5f6aw+7Z5jFaA=" crossorigin=anonymous></script>
<script defer src=/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js integrity="sha256-b2+Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC+NdcPIvZhzk=" crossorigin=anonymous></script></head><body dir=" ltr "><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>To Build, I Live</span></a></h2><div class=book-search><input type=text id=book-search-input placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><ul><li><a href=/forcasts/ target=_blank rel=noopener>forcasts / 预言</a></li><li><a href=/ideas/ target=_blank rel=noopener>ideas / 想法</a></li><li><a href=/okr/2022-08_iam26/ target=_blank rel=noopener>Todo this month</a></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class=book-header><div class="flex align-center justify-between"><label for=menu-control><img src=/svg/menu.svg class=book-icon alt=Menu></label>
<strong>text2vec 与矢量索引引擎</strong>
<label for=toc-control><img src=/svg/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class="hidden clearfix"><nav id=TableOfContents><ul><li><ul><li><a href=#2021-09-02-150643-星期四>2021-09-02 15:06:43 星期四</a></li><li><a href=#2021-09-01>2021-09-01</a></li></ul></li></ul></nav></aside></header><article class=markdown><p>1.milvus Milvus 是一款开源的、针对海量特征向量的相似性搜索引擎。
<a href=https://github.com/milvus-io/milvus>https://github.com/milvus-io/milvus</a>
文档 <a href=https://milvus.io/cn/>https://milvus.io/cn/</a></p><p>各种各样的语料库，非常全，而且可以下载
冷眼-风雨飘摇
专注于python、自然语言处理
<a href=https://cold-eye.github.io/post/nlp-corpus/>https://cold-eye.github.io/post/nlp-corpus/</a>
2021-09-01 13:39:39 星期三</p><ol start=2><li>text2vec引擎
推理速度可以满足实时性要求。https://github.com/NVIDIA/FasterTransformer</li></ol><p>ELECTRA模型
<a href=https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html>https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html</a>
中文预训练模型
<a href=https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html>https://www.leiphone.com/category/academic/i2yH9anJWkh8rd6r.html</a>
<a href=https://github.com/ymcui/Chinese-ELECTRA>https://github.com/ymcui/Chinese-ELECTRA</a>
科大讯飞某个主要技术负责人的github <a href=https://github.com/ymcui>https://github.com/ymcui</a>
中文训练数据集扩大9倍后的效果
<a href=https://www.jiqizhixin.com/articles/2020-10-26-11>https://www.jiqizhixin.com/articles/2020-10-26-11</a></p><p>苏剑林的反省：吐槽贴：用ELECTRA、ALBERT之前，你真的了解它们吗？
<a href=https://bbs.huaweicloud.com/blogs/226675>https://bbs.huaweicloud.com/blogs/226675</a>
苏剑林的博客
<a href=https://kexue.fm/>https://kexue.fm/</a></p><p>对bert 进行蒸馏，tinyBERT,推理速度提高9倍
<a href=https://zhuanlan.zhihu.com/p/94359189>https://zhuanlan.zhihu.com/p/94359189</a>
这是很棒的模型，一来可以直接训练，二来，可以用来蒸馏后使用</p><p>最后，github 上找出了一个质量很不错的答案，来解决计算文本相似度的问题
<a href=https://github.com/shibing624/text2vec>https://github.com/shibing624/text2vec</a>
具体实现包括wordVector 平均值法，以及small Bert 模型，重要的是这个是开箱可用的
<a href=https://www.sbert.net/index.html>https://www.sbert.net/index.html</a></p><h2 id=2021-09-02-150643-星期四>2021-09-02 15:06:43 星期四
<a class=anchor href=#2021-09-02-150643-%e6%98%9f%e6%9c%9f%e5%9b%9b>#</a></h2><p>fasterTransformer
<a href="https://baike.baidu.com/item/Faster%20Transformer/23737285?fr=aladdin">https://baike.baidu.com/item/Faster%20Transformer/23737285?fr=aladdin</a></p><p>最新的媲美Bert的模型
PRADO，pQRNN
<a href=https://zhuanlan.zhihu.com/p/257934777>https://zhuanlan.zhihu.com/p/257934777</a>
：印象是虽然小，但是没有放出的代码实现。也没有中文版本的踩坑记录</p><h2 id=2021-09-01>2021-09-01
<a class=anchor href=#2021-09-01>#</a></h2></article><footer class=book-footer><div class="flex flex-wrap justify-between"></div><script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script></footer><div class=book-comments></div><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><ul><li><a href=#2021-09-02-150643-星期四>2021-09-02 15:06:43 星期四</a></li><li><a href=#2021-09-01>2021-09-01</a></li></ul></li></ul></nav></div></aside></main></body></html>